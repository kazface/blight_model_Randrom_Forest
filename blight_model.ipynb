{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**File descriptions** (Use only this data for training your model!)\n",
    "\n",
    "    readonly/train.csv - the training set (all tickets issued 2004-2011)\n",
    "    readonly/test.csv - the test set (all tickets issued 2012-2016)\n",
    "    readonly/addresses.csv & readonly/latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def blight_model():\n",
    "\n",
    "    train = pd.read_csv(\"train.csv\", encoding=\"cp1252\")\n",
    "\n",
    "    test = pd.read_csv(\"test.csv\", encoding=\"cp1252\")\n",
    "\n",
    "    latlons = pd.read_csv('latlons.csv')\n",
    "    addresses = pd.read_csv('addresses.csv')\n",
    "\n",
    "    addresses_latlons = latlons.merge(addresses, how='inner', on='address')\n",
    "\n",
    "    train = train.merge(addresses_latlons, how='left', on='ticket_id')\n",
    "    test = test.merge(addresses_latlons, how='left', on='ticket_id')\n",
    "\n",
    "    #Training\n",
    "\n",
    "    train = train.dropna(subset=['compliance'])\n",
    "\n",
    "    #columns that not in test dataset\n",
    "    train_drop_list = ['payment_amount', 'payment_date','payment_status', 'balance_due', 'collection_status', 'compliance_detail']\n",
    "    full_drop_list = ['violation_zip_code', 'non_us_str_code', 'grafitti_status', 'violation_zip_code', 'mailing_address_str_number', 'violator_name']\n",
    "\n",
    "    train = train.drop(train_drop_list, axis=1)\n",
    "    train = train.drop(full_drop_list, axis=1)\n",
    "\n",
    "    test = test.drop(full_drop_list, axis=1)\n",
    "\n",
    "    train_str = train.select_dtypes(include=[object])\n",
    "\n",
    "    train_str = train_str.astype(str)\n",
    "\n",
    "    train_str = train_str.fillna('')\n",
    "\n",
    "    ohe = OneHotEncoder()\n",
    "\n",
    "    #for x in train_str.columns:\n",
    "    #    print(x, len(train_str[x].unique()))\n",
    "\n",
    "    #agency_name 5\n",
    "    #inspector_name 159\n",
    "    #violation_street_name 1716\n",
    "    #mailing_address_str_name 28441\n",
    "    #city 4093\n",
    "    #state 60\n",
    "    #zip_code 3499\n",
    "    #country 5\n",
    "    #ticket_issued_date 68097\n",
    "    #hearing_date 5971\n",
    "    #violation_code 189\n",
    "    #violation_description 207\n",
    "    #disposition 4\n",
    "    #address 71901\n",
    "\n",
    "    list_dummies = ['agency_name','inspector_name','state', 'country', 'violation_code', 'violation_description', 'disposition']\n",
    "\n",
    "    train_str_dummies = pd.get_dummies(train_str, columns=list_dummies)\n",
    "\n",
    "    train_str_le = train_str.drop(list_dummies, axis=1)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    train_str_le = train_str_le.apply(le.fit_transform)\n",
    "\n",
    "    train_df = train_str_dummies.drop(train_str_le.columns, axis=1).join(train_str_le)\n",
    "\n",
    "    train_float = train.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    #train_float.hist(figsize=(15,15))\n",
    "    #plt.show()\n",
    "\n",
    "    train_df = train_df.join(train_float)\n",
    "\n",
    "    train_df.compliance = train_df.compliance.astype(int)\n",
    "\n",
    "    train_df = train_df.fillna(train_df.mean())\n",
    "\n",
    "    X = train_df.drop('compliance', axis=1)\n",
    "\n",
    "    y = train_df.compliance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Testing prepocessing\n",
    "\n",
    "    test_str = test.select_dtypes(include=[object])\n",
    "\n",
    "    test_str = test_str.astype(str)\n",
    "\n",
    "    test_str = test_str.fillna('')\n",
    "\n",
    "    test_str_dummies = pd.get_dummies(test_str, columns=list_dummies)\n",
    "\n",
    "    test_str_le = test_str.drop(list_dummies, axis=1)\n",
    "\n",
    "    test_str_le = test_str_le.apply(le.fit_transform)\n",
    "\n",
    "    test_df = test_str_dummies.drop(test_str_le.columns, axis=1).join(test_str_le)\n",
    "\n",
    "    test_float = test.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    test_df = test_df.join(test_float)\n",
    "\n",
    "    test_df = test_df.fillna(test_df.mean())\n",
    "\n",
    "    #Test and train compare\n",
    "\n",
    "    union_columns = (np.intersect1d(train_df.columns, test_df.columns))\n",
    "\n",
    "    train_df = train_df.loc[:,np.insert(union_columns, [1], ['compliance'])]\n",
    "\n",
    "    test_df = test_df.loc[:, union_columns]\n",
    "\n",
    "    len(test_df.columns)\n",
    "\n",
    "    len(train_df.columns)\n",
    "\n",
    "    #Training\n",
    "\n",
    "    X = train_df.drop('compliance', axis=1)\n",
    "    y = train_df.compliance\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=5, n_estimators=30)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #testing\n",
    "\n",
    "    test['proba'] = clf.predict_proba(test_df)[:,1]\n",
    "\n",
    "\n",
    "    return test.set_index('ticket_id')['proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\batyr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.129604\n",
       "285362    0.090694\n",
       "285361    0.112928\n",
       "285338    0.079665\n",
       "285346    0.086922\n",
       "            ...   \n",
       "376496    0.053379\n",
       "376497    0.053379\n",
       "376499    0.080556\n",
       "376500    0.084053\n",
       "369851    0.224448\n",
       "Name: proba, Length: 61001, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blight_model()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
